# MonoDepth_Transfer
Monocular Depth Estimation from Image Using CNNs and Transfer Learning
![Alt text](depth_output_results/best_sofa.png )




Example use of monocular depth estimation from single image in real world
<p align="center">
  <img style="max-width:500px" src="https://github.com/kelvin-kkw/MonoDepth_Transfer/assets/105034699/2be71d1a-363e-4918-856e-e8b62d7b1e3a" width="" alt="RGBD Demo">
</p>
Multi-layered image depth effect in IOS version 16 (Released in September, 2022)
- This feature combined the monocular depth estimation of image with 3D object rendering with depth value to make occlusion aware 3D object rendering


How depth estimation is used in occlusion aware Augmented Reality 3D object rendering

<p align="center">
  <img style="max-width:500px" src="other_pictures/cat_occ.png" width="" alt="RGBD Demo">
</p>
ARcore occlusion dense depth AR effect (Released in October, 2020)
- This feature contains the use of Visual Simultaneous Localization and MappingÂ (vSLAM), the process of calculating the position and orientation of a camera with respect to its surroundings while simultaneously mapping the environment. With the use of vSLAM, the depth of scene is estimated and combine with 3D object rendering.





Traditional way of depth estimation before
<p align="center">
  <img style="max-width:500px" src="other_pictures/poster.png" width="" alt="RGBD Demo">
</p>


<p align="center">
  <img style="max-width:500px" src="other_pictures/poster.png" width="" alt="RGBD Demo">
</p>
